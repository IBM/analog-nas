{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analogainas.search_spaces.config_space import ConfigSpace\n",
    "from analogainas.search_spaces.autoencoder.autoencoder_config_space import AutoEncoderConfigSpace\n",
    "from analogainas.search_spaces.autoencoder.autoencoder_architecture import AutoEncoder\n",
    "from analogainas.search_spaces.dataloaders.autoencoder_structured_dataset import AutoEncoderStructuredDataset\n",
    "from analogainas.evaluators.evaluation_metrics import negative_mse_metric\n",
    "from aihwkit.simulator.configs import InferenceRPUConfig\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analogainas.analog_helpers.analog_helpers import create_rpu_config\n",
    "from aihwkit.simulator.configs import InferenceRPUConfig\n",
    "from aihwkit.simulator.configs.utils import WeightClipType\n",
    "from aihwkit.simulator.configs.utils import BoundManagementType\n",
    "from aihwkit.simulator.presets.utils import PresetIOParameters\n",
    "from aihwkit.inference.noise.pcm import PCMLikeNoiseModel\n",
    "from aihwkit.inference.compensation.drift import GlobalDriftCompensation\n",
    "from aihwkit.nn.conversion import convert_to_analog_mapped\n",
    "from aihwkit.nn import AnalogSequential\n",
    "from aihwkit.optim import AnalogSGD\n",
    "import aihwkit.inference.noise.pcm as pcm\n",
    "\n",
    "import aihwkit\n",
    "\n",
    "print(aihwkit.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_model = pcm.PCMLikeNoiseModel()\n",
    "optimal_rpu_config_dict = {'g_max': 256, 'tile_size': 64, 'dac_resolution': 128, 'adc_resolution': 256}\n",
    "rpu_config = create_rpu_config()\n",
    "optimal_rpu_config = create_rpu_config(g_max=optimal_rpu_config_dict['g_max'], tile_size=optimal_rpu_config_dict['tile_size'], dac_res=optimal_rpu_config_dict['dac_resolution'], adc_res=optimal_rpu_config_dict['adc_resolution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CS = AutoEncoderConfigSpace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CS.get_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CS.compute_cs_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = CS.sample_arch_uniformly(5)\n",
    "\n",
    "optimal_config={'embedding_dim': 256, 'encoder_convblock1_depth': 1, 'encoder_convblock1_kernel_size': 5, 'encoder_convblock1_filters': 64, 'encoder_convblock1_stride': 1, 'encoder_convblock2_depth': 1, 'encoder_convblock2_kernel_size': 3, 'encoder_convblock2_filters': 32, 'encoder_convblock2_stride': 1, 'encoder_convblock3_depth': 1, 'encoder_convblock3_kernel_size': 7, 'encoder_convblock3_filters': 16, 'encoder_convblock3_stride': 2}\n",
    "suboptimal_config= {'embedding_dim': 64, 'encoder_convblock1_depth': 3, 'encoder_convblock1_kernel_size': 5, 'encoder_convblock1_filters': 16, 'encoder_convblock1_stride': 1, 'encoder_convblock2_depth': 3, 'encoder_convblock2_kernel_size': 3, 'encoder_convblock2_filters': 8, 'encoder_convblock2_stride': 2, 'encoder_convblock3_depth': 3, 'encoder_convblock3_kernel_size': 7, 'encoder_convblock3_filters': 128, 'encoder_convblock3_stride': 1}\n",
    "\n",
    "new_optimal_config ={'embedding_dim': 2048,\n",
    " 'encoder_convblock1_depth': 1,\n",
    " 'encoder_convblock1_kernel_size': 3,\n",
    " 'encoder_convblock1_filters': 256,\n",
    " 'encoder_convblock1_stride': 1,\n",
    " 'encoder_convblock2_depth': 1,\n",
    " 'encoder_convblock2_kernel_size': 7,\n",
    " 'encoder_convblock2_filters': 256,\n",
    " 'encoder_convblock2_stride': 1,\n",
    " 'encoder_convblock3_depth': 3,\n",
    " 'encoder_convblock3_kernel_size': 3,\n",
    " 'encoder_convblock3_filters': 32,\n",
    " 'encoder_convblock3_stride': 2,\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_autoencoder = AutoEncoder(optimal_config, input_channels=3, input_size=(32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_performance(_autoencoder,_dataloader, normalize=True):\n",
    "    images, labels = next(iter(_dataloader))\n",
    "    _autoencoder = _autoencoder.to(torch.device('cpu'))\n",
    "    with torch.no_grad():\n",
    "        reconstructions = _autoencoder(images)\n",
    "    \n",
    "    def show_image(img_tensor, title=\"\", normalize=True):\n",
    "        img = img_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "        if normalize:\n",
    "            mean = np.array([0.4914, 0.4822, 0.4465])\n",
    "            std = np.array([0.2023, 0.1994, 0.2010])\n",
    "            img = (img * std) + mean\n",
    "        img = np.clip(img, 0, 1)\n",
    "        \n",
    "        plt.imshow(img)\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=2, ncols=8, figsize=(16, 4))\n",
    "    \n",
    "    for i in range(8):\n",
    "        plt.sca(axes[0, i])\n",
    "        show_image(images[i], title=\"Original\")\n",
    "        plt.sca(axes[1, i])\n",
    "        show_image(reconstructions[i], title=\"Reconstructed\", normalize=normalize)\n",
    "    \n",
    "    sample_autoencoder.to(torch.device('cpu'))\n",
    "    negative_mse = negative_mse_metric(_dataloader, _autoencoder)\n",
    "    print(\"Negative MSE: \", sum(negative_mse)/len(negative_mse))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                         (0.2023, 0.1994, 0.2010)) \n",
    "])\n",
    "\n",
    "train_cifar_dataset = AutoEncoderStructuredDataset(\n",
    "    torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(train_cifar_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "test_cifar_dataset = AutoEncoderStructuredDataset(\n",
    "    torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(test_cifar_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(sample_autoencoder.parameters(), lr=1e-3)\n",
    "optimizer = optim.SGD(sample_autoencoder.parameters(), lr=1e-3)\n",
    "\n",
    "sample_autoencoder = sample_autoencoder.to(device)\n",
    "epochs = 15\n",
    "sample_autoencoder.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for batch_idx, (images, _) in enumerate(dataloader):\n",
    "        images = images.to(device)\n",
    "        recon = sample_autoencoder(images)\n",
    "        loss = criterion(recon, images)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 50 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}], Step [{batch_idx}], Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_performance(sample_autoencoder, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "analog_sample_autoencoder = sample_autoencoder.to(torch.device('cpu'))\n",
    "analog_sample_autoencoder.eval()\n",
    "analog_sample_autoencoder = convert_to_analog_mapped(sample_autoencoder, rpu_config)\n",
    "\n",
    "#analog_sample_autoencoder.drift_analog_weights(24 * 60 * 60 * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"One Day Performance\")\n",
    "show_performance(analog_sample_autoencoder, dataloader, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analog_sample_autoencoder.drift_analog_weights(24 * 60 * 60 * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"One Month Performance\")\n",
    "show_performance(analog_sample_autoencoder, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "analog_sample_autoencoder = sample_autoencoder.to(torch.device('cpu'))\n",
    "analog_sample_autoencoder.eval()\n",
    "analog_sample_autoencoder = convert_to_analog_mapped(sample_autoencoder, optimal_rpu_config)\n",
    "\n",
    "analog_sample_autoencoder.drift_analog_weights(24 * 60 * 60 * 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"One Day Performance (Optimal RPU)\")\n",
    "show_performance(analog_sample_autoencoder, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analog_sample_autoencoder.drift_analog_weights(24 * 60 * 60 * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"One Month Performance (Optimal RPU)\")\n",
    "show_performance(analog_sample_autoencoder, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
