{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analogainas.search_spaces.config_space import ConfigSpace\n",
    "## Default Search Space\n",
    "# We will be using the default search space\n",
    "CS = ConfigSpace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['out_channel0', 'M', 'R1', 'R2', 'R3', 'R4', 'R5', 'convblock1', 'widenfact1', 'B1', 'convblock2', 'widenfact2', 'B2', 'convblock3', 'widenfact3', 'B3', 'convblock4', 'widenfact4', 'B4', 'convblock5', 'widenfact5', 'B5']\n"
     ]
    }
   ],
   "source": [
    "# You can extract the full list of hyperparameters using:\n",
    "CS.get_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100663296"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the size of the search space\n",
    "CS.compute_cs_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'results' directory already exists.\n",
      "\n",
      "Search 0 started\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m EAOptimizer(evaluator, population_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, nb_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      9\u001b[0m worker \u001b[38;5;241m=\u001b[39m Worker(CS, optimizer\u001b[38;5;241m=\u001b[39moptimizer, runs\u001b[38;5;241m=\u001b[39mNB_RUN)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mworker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Masters/NYU_Courses/Spring_2024/High Performance Machine Learning/Project/Supernet_Project/Final_Project/analog-nas-unet/analogainas/search_algorithms/worker.py:42\u001b[0m, in \u001b[0;36mWorker.search\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mruns):\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m started\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i))\n\u001b[0;32m---> 42\u001b[0m     best_config, best_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig_space\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults/best_results_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m best_config\u001b[38;5;241m.\u001b[39mkeys():\n",
      "File \u001b[0;32m~/Masters/NYU_Courses/Spring_2024/High Performance Machine Learning/Project/Supernet_Project/Final_Project/analog-nas-unet/analogainas/search_algorithms/ea_optimized.py:100\u001b[0m, in \u001b[0;36mEAOptimizer.run\u001b[0;34m(self, cs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, cs):\n\u001b[0;32m--> 100\u001b[0m     P \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_initial_population\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     best_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    102\u001b[0m     best_x \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpopulation_size\n",
      "File \u001b[0;32m~/Masters/NYU_Courses/Spring_2024/High Performance Machine Learning/Project/Supernet_Project/Final_Project/analog-nas-unet/analogainas/search_algorithms/ea_optimized.py:86\u001b[0m, in \u001b[0;36mEAOptimizer.generate_initial_population\u001b[0;34m(self, cs)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(P))\n\u001b[1;32m     84\u001b[0m _, slope \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msurrogate\u001b[38;5;241m.\u001b[39mquery_pop(P)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msatisfied_constrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(slope):\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT_AVM:\n",
      "File \u001b[0;32m~/Masters/NYU_Courses/Spring_2024/High Performance Machine Learning/Project/Supernet_Project/Final_Project/analog-nas-unet/analogainas/search_algorithms/ea_optimized.py:93\u001b[0m, in \u001b[0;36mEAOptimizer.satisfied_constrained\u001b[0;34m(self, P)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msatisfied_constrained\u001b[39m(\u001b[38;5;28mself\u001b[39m, P):\n\u001b[0;32m---> 93\u001b[0m     _, slope \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msurrogate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_pop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(slope):\n\u001b[1;32m     95\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT_AVM:\n",
      "File \u001b[0;32m~/Masters/NYU_Courses/Spring_2024/High Performance Machine Learning/Project/Supernet_Project/Final_Project/analog-nas-unet/analogainas/evaluators/xgboost.py:88\u001b[0m, in \u001b[0;36mXGBoostEvaluator.query_pop\u001b[0;34m(self, P)\u001b[0m\n\u001b[1;32m     86\u001b[0m     x_test\u001b[38;5;241m.\u001b[39mappend(arch)\n\u001b[1;32m     87\u001b[0m x_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(x_test)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mranker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavm_predictor\u001b[38;5;241m.\u001b[39mpredict(x_test)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/supernetwork_nas/lib/python3.9/site-packages/xgboost/sklearn.py:1164\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[0;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m   1126\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1127\u001b[0m     X: ArrayLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     iteration_range: Optional[Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1132\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict with `X`.  If the model is trained with early stopping, then\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;124;03m    :py:attr:`best_iteration` is used automatically. The estimator uses\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;124;03m    `inplace_predict` by default and falls back to using :py:class:`DMatrix` if\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1162\u001b[0m \n\u001b[1;32m   1163\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1164\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[1;32m   1165\u001b[0m         iteration_range \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_iteration_range(iteration_range)\n\u001b[1;32m   1166\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n",
      "File \u001b[0;32m/opt/anaconda3/envs/supernetwork_nas/lib/python3.9/contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/supernetwork_nas/lib/python3.9/site-packages/xgboost/config.py:181\u001b[0m, in \u001b[0;36mconfig_context\u001b[0;34m(**new_config)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;129m@contextmanager\u001b[39m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;129m@config_doc\u001b[39m(\n\u001b[1;32m    157\u001b[0m     header\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    178\u001b[0m )\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfig_context\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnew_config: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[\u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[1;32m    180\u001b[0m     old_config \u001b[38;5;241m=\u001b[39m get_config()\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m--> 181\u001b[0m     \u001b[43mset_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    184\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/supernetwork_nas/lib/python3.9/site-packages/xgboost/config.py:108\u001b[0m, in \u001b[0;36mconfig_doc.<locals>.config_doc_decorator.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/supernetwork_nas/lib/python3.9/site-packages/xgboost/config.py:132\u001b[0m, in \u001b[0;36mset_config\u001b[0;34m(**new_config)\u001b[0m\n\u001b[1;32m    130\u001b[0m         not_none[k] \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m    131\u001b[0m config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(not_none)\n\u001b[0;32m--> 132\u001b[0m _check_call(_LIB\u001b[38;5;241m.\u001b[39mXGBSetGlobalConfig(\u001b[43mc_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/supernetwork_nas/lib/python3.9/site-packages/xgboost/core.py:421\u001b[0m, in \u001b[0;36mc_str\u001b[0;34m(string)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mc_str\u001b[39m(string: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p:\n\u001b[1;32m    420\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convert a python string to cstring.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 421\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_char_p\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstring\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load the evaluator\n",
    "from analogainas.evaluators.xgboost import XGBoostEvaluator\n",
    "evaluator = XGBoostEvaluator()\n",
    "from analogainas.search_algorithms.ea_optimized import EAOptimizer\n",
    "from analogainas.search_algorithms.worker import Worker\n",
    "NB_RUN = 5\n",
    "\n",
    "optimizer = EAOptimizer(evaluator, population_size=20, nb_iter=10)\n",
    "worker = Worker(CS, optimizer=optimizer, runs=NB_RUN)\n",
    "worker.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best architecture accuracy:  [0.9467617]\n",
      "Standard deviation of accuracy over 5 runs: 0.009903628916952234\n",
      "Best architecture:  {'out_channel0': 16, 'M': 1, 'R1': 1, 'R2': 0, 'R3': 0, 'R4': 0, 'R5': 0, 'convblock1': 1, 'widenfact1': 0.673694114891254, 'B1': 3, 'convblock2': 0, 'widenfact2': 0, 'B2': 0, 'convblock3': 0, 'widenfact3': 0, 'B3': 0, 'convblock4': 0, 'widenfact4': 0, 'B4': 0, 'convblock5': 0, 'widenfact5': 0, 'B5': 0}\n"
     ]
    }
   ],
   "source": [
    "worker.result_summary()\n",
    "best_config = worker.best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'out_channel0': 16,\n",
       " 'M': 1,\n",
       " 'R1': 1,\n",
       " 'R2': 0,\n",
       " 'R3': 0,\n",
       " 'R4': 0,\n",
       " 'R5': 0,\n",
       " 'convblock1': 1,\n",
       " 'widenfact1': 0.673694114891254,\n",
       " 'B1': 3,\n",
       " 'convblock2': 0,\n",
       " 'widenfact2': 0,\n",
       " 'B2': 0,\n",
       " 'convblock3': 0,\n",
       " 'widenfact3': 0,\n",
       " 'B3': 0,\n",
       " 'convblock4': 0,\n",
       " 'widenfact4': 0,\n",
       " 'B4': 0,\n",
       " 'convblock5': 0,\n",
       " 'widenfact5': 0,\n",
       " 'B5': 0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analogainas.search_spaces.resnet_macro_architecture import Network\n",
    "from analogainas.search_spaces.train import train_config_unet\n",
    "from analogainas.utils import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Building the Optimal Sub-network\n",
    "model = Network(best_config)\n",
    "input_tensor = torch.rand((1, 3, 32, 32))\n",
    "output = model(input_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1808993\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config_hc = {'out_channel0': 16,\n",
    " 'M': 4,\n",
    " 'R1': 2,\n",
    " 'R2': 1,\n",
    " 'R3': 2,\n",
    " 'R4': 1,\n",
    " 'R5': 0,\n",
    " 'convblock1': 2,\n",
    " 'widenfact1': 0.7939218808815371,\n",
    " 'B1': 2,\n",
    " 'convblock2': 2,\n",
    " 'widenfact2': 0.5256597823796261,\n",
    " 'B2': 4,\n",
    " 'convblock3': 1,\n",
    " 'widenfact3': 0.5364357109292749,\n",
    " 'B3': 2,\n",
    " 'convblock4': 2,\n",
    " 'widenfact4': 0.5073309835858459,\n",
    " 'B4': 3,\n",
    " 'convblock5': 0,\n",
    " 'widenfact5': 0,\n",
    " 'B5': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network(\n",
      "  (model): Sequential(\n",
      "    (Main_blocks): Sequential(\n",
      "      (Conv_0): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (BN_0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (Group_1): ResidualGroup(\n",
      "        (group): Sequential(\n",
      "          (Block_1): BasicBlock(\n",
      "            (branches): ModuleList(\n",
      "              (0): ResidualBranch(\n",
      "                (residual_branch): Sequential(\n",
      "                  (Branch_1:ReLU_1): ReLU()\n",
      "                  (Branch_1:Conv_1): Conv2d(16, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_1:BN_1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (Branch_1:ReLU_2): ReLU()\n",
      "                  (Branch_1:Conv_2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_1:BN_2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "              (1): ResidualBranch(\n",
      "                (residual_branch): Sequential(\n",
      "                  (Branch_2:ReLU_1): ReLU()\n",
      "                  (Branch_2:Conv_1): Conv2d(16, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_2:BN_1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (Branch_2:ReLU_2): ReLU()\n",
      "                  (Branch_2:Conv_2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_2:BN_2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (skip): Sequential(\n",
      "              (Skip_connection): SkipConnection(\n",
      "                (s1): Sequential(\n",
      "                  (Skip_1_AvgPool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "                  (Skip_1_Conv): Conv2d(16, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                )\n",
      "                (s2): Sequential(\n",
      "                  (Skip_2_AvgPool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "                  (Skip_2_Conv): Conv2d(16, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                )\n",
      "                (batch_norm): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (Block_2): BasicBlock(\n",
      "            (branches): ModuleList(\n",
      "              (0): ResidualBranch(\n",
      "                (residual_branch): Sequential(\n",
      "                  (Branch_1:ReLU_1): ReLU()\n",
      "                  (Branch_1:Conv_1): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_1:BN_1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (Branch_1:ReLU_2): ReLU()\n",
      "                  (Branch_1:Conv_2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_1:BN_2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "              (1): ResidualBranch(\n",
      "                (residual_branch): Sequential(\n",
      "                  (Branch_2:ReLU_1): ReLU()\n",
      "                  (Branch_2:Conv_1): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_2:BN_1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (Branch_2:ReLU_2): ReLU()\n",
      "                  (Branch_2:Conv_2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_2:BN_2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (skip): Sequential()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (Group_2): ResidualGroup(\n",
      "        (group): Sequential(\n",
      "          (Block_1): BasicBlock(\n",
      "            (branches): ModuleList(\n",
      "              (0): ResidualBranch(\n",
      "                (residual_branch): Sequential(\n",
      "                  (Branch_1:ReLU_1): ReLU()\n",
      "                  (Branch_1:Conv_1): Conv2d(20, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_1:BN_1): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (Branch_1:ReLU_2): ReLU()\n",
      "                  (Branch_1:Conv_2): Conv2d(38, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_1:BN_2): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "              (1): ResidualBranch(\n",
      "                (residual_branch): Sequential(\n",
      "                  (Branch_2:ReLU_1): ReLU()\n",
      "                  (Branch_2:Conv_1): Conv2d(20, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_2:BN_1): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (Branch_2:ReLU_2): ReLU()\n",
      "                  (Branch_2:Conv_2): Conv2d(38, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_2:BN_2): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "              (2): ResidualBranch(\n",
      "                (residual_branch): Sequential(\n",
      "                  (Branch_3:ReLU_1): ReLU()\n",
      "                  (Branch_3:Conv_1): Conv2d(20, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_3:BN_1): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (Branch_3:ReLU_2): ReLU()\n",
      "                  (Branch_3:Conv_2): Conv2d(38, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_3:BN_2): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "              (3): ResidualBranch(\n",
      "                (residual_branch): Sequential(\n",
      "                  (Branch_4:ReLU_1): ReLU()\n",
      "                  (Branch_4:Conv_1): Conv2d(20, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_4:BN_1): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (Branch_4:ReLU_2): ReLU()\n",
      "                  (Branch_4:Conv_2): Conv2d(38, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_4:BN_2): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (skip): Sequential(\n",
      "              (Skip_connection): SkipConnection(\n",
      "                (s1): Sequential(\n",
      "                  (Skip_1_AvgPool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "                  (Skip_1_Conv): Conv2d(20, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                )\n",
      "                (s2): Sequential(\n",
      "                  (Skip_2_AvgPool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "                  (Skip_2_Conv): Conv2d(20, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                )\n",
      "                (batch_norm): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (Group_3): ResidualGroup(\n",
      "        (group): Sequential(\n",
      "          (Block_1): BasicBlock(\n",
      "            (branches): ModuleList(\n",
      "              (0): ResidualBranch(\n",
      "                (residual_branch): Sequential(\n",
      "                  (Branch_1:ReLU_1): ReLU()\n",
      "                  (Branch_1:Conv_1): Conv2d(38, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_1:BN_1): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (Branch_1:ReLU_2): ReLU()\n",
      "                  (Branch_1:Conv_2): Conv2d(70, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_1:BN_2): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "              (1): ResidualBranch(\n",
      "                (residual_branch): Sequential(\n",
      "                  (Branch_2:ReLU_1): ReLU()\n",
      "                  (Branch_2:Conv_1): Conv2d(38, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_2:BN_1): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (Branch_2:ReLU_2): ReLU()\n",
      "                  (Branch_2:Conv_2): Conv2d(70, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_2:BN_2): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (skip): Sequential(\n",
      "              (Skip_connection): SkipConnection(\n",
      "                (s1): Sequential(\n",
      "                  (Skip_1_AvgPool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "                  (Skip_1_Conv): Conv2d(38, 35, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                )\n",
      "                (s2): Sequential(\n",
      "                  (Skip_2_AvgPool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "                  (Skip_2_Conv): Conv2d(38, 35, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                )\n",
      "                (batch_norm): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (Block_2): BasicBlock(\n",
      "            (branches): ModuleList(\n",
      "              (0): ResidualBranch(\n",
      "                (residual_branch): Sequential(\n",
      "                  (Branch_1:ReLU_1): ReLU()\n",
      "                  (Branch_1:Conv_1): Conv2d(70, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_1:BN_1): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (Branch_1:ReLU_2): ReLU()\n",
      "                  (Branch_1:Conv_2): Conv2d(70, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_1:BN_2): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "              (1): ResidualBranch(\n",
      "                (residual_branch): Sequential(\n",
      "                  (Branch_2:ReLU_1): ReLU()\n",
      "                  (Branch_2:Conv_1): Conv2d(70, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_2:BN_1): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (Branch_2:ReLU_2): ReLU()\n",
      "                  (Branch_2:Conv_2): Conv2d(70, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_2:BN_2): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (skip): Sequential()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (Group_4): ResidualGroup(\n",
      "        (group): Sequential(\n",
      "          (Block_1): BasicBlock(\n",
      "            (branches): ModuleList(\n",
      "              (0): ResidualBranch(\n",
      "                (residual_branch): Sequential(\n",
      "                  (Branch_1:ReLU_1): ReLU()\n",
      "                  (Branch_1:Conv_1): Conv2d(70, 137, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_1:BN_1): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (Branch_1:ReLU_2): ReLU()\n",
      "                  (Branch_1:Conv_2): Conv2d(137, 137, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_1:BN_2): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "              (1): ResidualBranch(\n",
      "                (residual_branch): Sequential(\n",
      "                  (Branch_2:ReLU_1): ReLU()\n",
      "                  (Branch_2:Conv_1): Conv2d(70, 137, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_2:BN_1): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (Branch_2:ReLU_2): ReLU()\n",
      "                  (Branch_2:Conv_2): Conv2d(137, 137, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_2:BN_2): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "              (2): ResidualBranch(\n",
      "                (residual_branch): Sequential(\n",
      "                  (Branch_3:ReLU_1): ReLU()\n",
      "                  (Branch_3:Conv_1): Conv2d(70, 137, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_3:BN_1): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (Branch_3:ReLU_2): ReLU()\n",
      "                  (Branch_3:Conv_2): Conv2d(137, 137, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (Branch_3:BN_2): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (skip): Sequential(\n",
      "              (Skip_connection): SkipConnection(\n",
      "                (s1): Sequential(\n",
      "                  (Skip_1_AvgPool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "                  (Skip_1_Conv): Conv2d(70, 68, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                )\n",
      "                (s2): Sequential(\n",
      "                  (Skip_2_AvgPool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "                  (Skip_2_Conv): Conv2d(70, 69, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                )\n",
      "                (batch_norm): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (ReLU_0): ReLU(inplace=True)\n",
      "      (AveragePool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
      "    )\n",
      "  )\n",
      "  (blocks): Sequential(\n",
      "    (Conv_0): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (BN_0): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (Group_1): ResidualGroup(\n",
      "      (group): Sequential(\n",
      "        (Block_1): BasicBlock(\n",
      "          (branches): ModuleList(\n",
      "            (0): ResidualBranch(\n",
      "              (residual_branch): Sequential(\n",
      "                (Branch_1:ReLU_1): ReLU()\n",
      "                (Branch_1:Conv_1): Conv2d(16, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_1:BN_1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (Branch_1:ReLU_2): ReLU()\n",
      "                (Branch_1:Conv_2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_1:BN_2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (1): ResidualBranch(\n",
      "              (residual_branch): Sequential(\n",
      "                (Branch_2:ReLU_1): ReLU()\n",
      "                (Branch_2:Conv_1): Conv2d(16, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_2:BN_1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (Branch_2:ReLU_2): ReLU()\n",
      "                (Branch_2:Conv_2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_2:BN_2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (skip): Sequential(\n",
      "            (Skip_connection): SkipConnection(\n",
      "              (s1): Sequential(\n",
      "                (Skip_1_AvgPool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "                (Skip_1_Conv): Conv2d(16, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (s2): Sequential(\n",
      "                (Skip_2_AvgPool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "                (Skip_2_Conv): Conv2d(16, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (batch_norm): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (Block_2): BasicBlock(\n",
      "          (branches): ModuleList(\n",
      "            (0): ResidualBranch(\n",
      "              (residual_branch): Sequential(\n",
      "                (Branch_1:ReLU_1): ReLU()\n",
      "                (Branch_1:Conv_1): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_1:BN_1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (Branch_1:ReLU_2): ReLU()\n",
      "                (Branch_1:Conv_2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_1:BN_2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (1): ResidualBranch(\n",
      "              (residual_branch): Sequential(\n",
      "                (Branch_2:ReLU_1): ReLU()\n",
      "                (Branch_2:Conv_1): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_2:BN_1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (Branch_2:ReLU_2): ReLU()\n",
      "                (Branch_2:Conv_2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_2:BN_2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (skip): Sequential()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (Group_2): ResidualGroup(\n",
      "      (group): Sequential(\n",
      "        (Block_1): BasicBlock(\n",
      "          (branches): ModuleList(\n",
      "            (0): ResidualBranch(\n",
      "              (residual_branch): Sequential(\n",
      "                (Branch_1:ReLU_1): ReLU()\n",
      "                (Branch_1:Conv_1): Conv2d(20, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_1:BN_1): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (Branch_1:ReLU_2): ReLU()\n",
      "                (Branch_1:Conv_2): Conv2d(38, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_1:BN_2): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (1): ResidualBranch(\n",
      "              (residual_branch): Sequential(\n",
      "                (Branch_2:ReLU_1): ReLU()\n",
      "                (Branch_2:Conv_1): Conv2d(20, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_2:BN_1): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (Branch_2:ReLU_2): ReLU()\n",
      "                (Branch_2:Conv_2): Conv2d(38, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_2:BN_2): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (2): ResidualBranch(\n",
      "              (residual_branch): Sequential(\n",
      "                (Branch_3:ReLU_1): ReLU()\n",
      "                (Branch_3:Conv_1): Conv2d(20, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_3:BN_1): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (Branch_3:ReLU_2): ReLU()\n",
      "                (Branch_3:Conv_2): Conv2d(38, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_3:BN_2): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (3): ResidualBranch(\n",
      "              (residual_branch): Sequential(\n",
      "                (Branch_4:ReLU_1): ReLU()\n",
      "                (Branch_4:Conv_1): Conv2d(20, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_4:BN_1): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (Branch_4:ReLU_2): ReLU()\n",
      "                (Branch_4:Conv_2): Conv2d(38, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_4:BN_2): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (skip): Sequential(\n",
      "            (Skip_connection): SkipConnection(\n",
      "              (s1): Sequential(\n",
      "                (Skip_1_AvgPool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "                (Skip_1_Conv): Conv2d(20, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (s2): Sequential(\n",
      "                (Skip_2_AvgPool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "                (Skip_2_Conv): Conv2d(20, 19, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (batch_norm): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (Group_3): ResidualGroup(\n",
      "      (group): Sequential(\n",
      "        (Block_1): BasicBlock(\n",
      "          (branches): ModuleList(\n",
      "            (0): ResidualBranch(\n",
      "              (residual_branch): Sequential(\n",
      "                (Branch_1:ReLU_1): ReLU()\n",
      "                (Branch_1:Conv_1): Conv2d(38, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_1:BN_1): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (Branch_1:ReLU_2): ReLU()\n",
      "                (Branch_1:Conv_2): Conv2d(70, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_1:BN_2): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (1): ResidualBranch(\n",
      "              (residual_branch): Sequential(\n",
      "                (Branch_2:ReLU_1): ReLU()\n",
      "                (Branch_2:Conv_1): Conv2d(38, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_2:BN_1): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (Branch_2:ReLU_2): ReLU()\n",
      "                (Branch_2:Conv_2): Conv2d(70, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_2:BN_2): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (skip): Sequential(\n",
      "            (Skip_connection): SkipConnection(\n",
      "              (s1): Sequential(\n",
      "                (Skip_1_AvgPool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "                (Skip_1_Conv): Conv2d(38, 35, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (s2): Sequential(\n",
      "                (Skip_2_AvgPool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "                (Skip_2_Conv): Conv2d(38, 35, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (batch_norm): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (Block_2): BasicBlock(\n",
      "          (branches): ModuleList(\n",
      "            (0): ResidualBranch(\n",
      "              (residual_branch): Sequential(\n",
      "                (Branch_1:ReLU_1): ReLU()\n",
      "                (Branch_1:Conv_1): Conv2d(70, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_1:BN_1): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (Branch_1:ReLU_2): ReLU()\n",
      "                (Branch_1:Conv_2): Conv2d(70, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_1:BN_2): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (1): ResidualBranch(\n",
      "              (residual_branch): Sequential(\n",
      "                (Branch_2:ReLU_1): ReLU()\n",
      "                (Branch_2:Conv_1): Conv2d(70, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_2:BN_1): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (Branch_2:ReLU_2): ReLU()\n",
      "                (Branch_2:Conv_2): Conv2d(70, 70, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_2:BN_2): BatchNorm2d(70, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (skip): Sequential()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (Group_4): ResidualGroup(\n",
      "      (group): Sequential(\n",
      "        (Block_1): BasicBlock(\n",
      "          (branches): ModuleList(\n",
      "            (0): ResidualBranch(\n",
      "              (residual_branch): Sequential(\n",
      "                (Branch_1:ReLU_1): ReLU()\n",
      "                (Branch_1:Conv_1): Conv2d(70, 137, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_1:BN_1): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (Branch_1:ReLU_2): ReLU()\n",
      "                (Branch_1:Conv_2): Conv2d(137, 137, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_1:BN_2): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (1): ResidualBranch(\n",
      "              (residual_branch): Sequential(\n",
      "                (Branch_2:ReLU_1): ReLU()\n",
      "                (Branch_2:Conv_1): Conv2d(70, 137, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_2:BN_1): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (Branch_2:ReLU_2): ReLU()\n",
      "                (Branch_2:Conv_2): Conv2d(137, 137, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_2:BN_2): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "            (2): ResidualBranch(\n",
      "              (residual_branch): Sequential(\n",
      "                (Branch_3:ReLU_1): ReLU()\n",
      "                (Branch_3:Conv_1): Conv2d(70, 137, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_3:BN_1): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (Branch_3:ReLU_2): ReLU()\n",
      "                (Branch_3:Conv_2): Conv2d(137, 137, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (Branch_3:BN_2): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (skip): Sequential(\n",
      "            (Skip_connection): SkipConnection(\n",
      "              (s1): Sequential(\n",
      "                (Skip_1_AvgPool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "                (Skip_1_Conv): Conv2d(70, 68, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (s2): Sequential(\n",
      "                (Skip_2_AvgPool): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "                (Skip_2_Conv): Conv2d(70, 69, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              )\n",
      "              (batch_norm): BatchNorm2d(137, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ReLU_0): ReLU(inplace=True)\n",
      "    (AveragePool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
      "  )\n",
      "  (fc): Linear(in_features=60417, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x989825 and 60417x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m Network(best_config_hc)\n\u001b[1;32m      5\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrand((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m96\u001b[39m, \u001b[38;5;241m96\u001b[39m))\n\u001b[0;32m----> 6\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mdim_dict)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/supernetwork_nas/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/supernetwork_nas/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Masters/NYU_Courses/Spring_2024/High Performance Machine Learning/Project/Supernet_Project/Final_Project/analog-nas-unet/analogainas/search_spaces/resnet_macro_architecture.py:284\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    281\u001b[0m     feature_maps_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;28mround\u001b[39m(feature_maps_in \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwiden_factors[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroup_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(m)])\n\u001b[1;32m    283\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\u001b[38;5;241m.\u001b[39madd_module(\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroup_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(m),\n\u001b[1;32m    286\u001b[0m         ResidualGroup(\n\u001b[1;32m    287\u001b[0m             block,\n\u001b[1;32m    288\u001b[0m             feature_maps_in,\n\u001b[1;32m    289\u001b[0m             feature_maps_out,\n\u001b[1;32m    290\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresidual_blocks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroup_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(m)],\n\u001b[1;32m    291\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters_size[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroup_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(m)],\n\u001b[1;32m    292\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres_branches[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGroup_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(m)],\n\u001b[1;32m    293\u001b[0m             \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    294\u001b[0m         ),\n\u001b[1;32m    295\u001b[0m     )\n\u001b[1;32m    296\u001b[0m     feature_maps_in \u001b[38;5;241m=\u001b[39m feature_maps_out\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_maps_out \u001b[38;5;241m=\u001b[39m feature_maps_out\n",
      "File \u001b[0;32m/opt/anaconda3/envs/supernetwork_nas/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/supernetwork_nas/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/supernetwork_nas/lib/python3.9/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x989825 and 60417x10)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric Functions for Training Nuclei Segmentation\n",
    "\n",
    "# IOU Score and DICE Coefficients\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def iou_score(output, target):\n",
    "    smooth = 1e-5\n",
    "\n",
    "    if torch.is_tensor(output):\n",
    "        output = torch.sigmoid(output).data.cpu().numpy()\n",
    "    if torch.is_tensor(target):\n",
    "        target = target.data.cpu().numpy()\n",
    "    output_ = output > 0.5\n",
    "    target_ = target > 0.5\n",
    "    intersection = (output_ & target_).sum()\n",
    "    union = (output_ | target_).sum()\n",
    "\n",
    "    return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "\n",
    "def dice_coef(output, target):\n",
    "    smooth = 1e-5\n",
    "\n",
    "    output = torch.sigmoid(output).view(-1).data.cpu().numpy()\n",
    "    target = target.view(-1).data.cpu().numpy()\n",
    "    intersection = (output * target).sum()\n",
    "\n",
    "    return (2. * intersection + smooth) / \\\n",
    "        (output.sum() + target.sum() + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "import argparse\n",
    "def str2bool(v):\n",
    "    if v.lower() in ['true', 1]:\n",
    "        return True\n",
    "    elif v.lower() in ['false', 0]:\n",
    "        return False\n",
    "    else:\n",
    "        raise argparse.ArgumentTypeError('Boolean value expected.')\n",
    "\n",
    "\n",
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Functions for Segmentation\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BCEDiceLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        bce = F.binary_cross_entropy_with_logits(input, target)\n",
    "        smooth = 1e-5\n",
    "        input = torch.sigmoid(input)\n",
    "        num = target.size(0)\n",
    "        input = input.view(num, -1)\n",
    "        target = target.view(num, -1)\n",
    "        intersection = (input * target)\n",
    "        dice = (2. * intersection.sum(1) + smooth) / (input.sum(1) + target.sum(1) + smooth)\n",
    "        dice = 1 - dice.sum() / num\n",
    "        return 0.5 * bce + dice\n",
    "\n",
    "\n",
    "class LovaszHingeLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        input = input.squeeze(1)\n",
    "        target = target.squeeze(1)\n",
    "        loss = lovasz_hinge(input, target, per_image=True)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "        'spatial_dims': 2,  # it's 2 for 2D images; would be 3 for 3D images\n",
    "        'in_channels': 3,   # e.g., 3 for RGB input images\n",
    "        'out_channels': 1,  # e.g., 1 for binary segmentation tasks\n",
    "        'channels': (16, 32, 64, 128, 256), # Number of channels in the inner layers\n",
    "        'strides': (2, 2, 2, 2),\n",
    "        'name': None,\n",
    "        'epochs': 200,\n",
    "        'batch_size': 64,\n",
    "        'arch': 'UNet',\n",
    "        'deep_supervision': False,\n",
    "        'input_channels': 3,\n",
    "        'num_classes': 1,\n",
    "        'input_w': 96,\n",
    "        'input_h': 96,\n",
    "        'loss': 'BCEDiceLoss',\n",
    "        'dataset': 'dsb2018_96',\n",
    "        'img_ext': '.png',\n",
    "        'mask_ext': '.png',\n",
    "        'optimizer': 'SGD',\n",
    "        'lr': 1e-3,\n",
    "        'momentum': 0.9,\n",
    "        'weight_decay': 1e-4,\n",
    "        'nesterov': False,\n",
    "        'scheduler': 'CosineAnnealingLR',\n",
    "        'min_lr': 1e-5,\n",
    "        'factor': 0.1,\n",
    "        'patience': 2,\n",
    "        'milestones': '1,2',\n",
    "        'gamma': 2/3,\n",
    "        'early_stopping': -1,\n",
    "        'num_workers': 4\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digital Training imports\n",
    "import argparse\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import yaml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_NAMES = ['BCEDiceLoss', 'LovaszHingeLoss']\n",
    "LOSS_NAMES.append('BCEWithLogitsLoss')\n",
    "\n",
    "def train(config, train_loader, model, criterion, optimizer):\n",
    "    avg_meters = {'loss': AverageMeter(),\n",
    "                  'iou': AverageMeter()}\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    pbar = tqdm(total=len(train_loader))\n",
    "    for input, target, _ in train_loader:\n",
    "        input = input.cuda()\n",
    "        target = target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        if config['deep_supervision']:\n",
    "            outputs = model(input)\n",
    "            loss = 0\n",
    "            for output in outputs:\n",
    "                loss += criterion(output, target)\n",
    "            loss /= len(outputs)\n",
    "            iou = iou_score(outputs[-1], target)\n",
    "        else:\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "            iou = iou_score(output, target)\n",
    "\n",
    "        # compute gradient and do optimizing step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_meters['loss'].update(loss.item(), input.size(0))\n",
    "        avg_meters['iou'].update(iou, input.size(0))\n",
    "\n",
    "        postfix = OrderedDict([\n",
    "            ('loss', avg_meters['loss'].avg),\n",
    "            ('iou', avg_meters['iou'].avg),\n",
    "        ])\n",
    "        pbar.set_postfix(postfix)\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "    return OrderedDict([('loss', avg_meters['loss'].avg),\n",
    "                        ('iou', avg_meters['iou'].avg)])\n",
    "\n",
    "def validate(config, val_loader, model, criterion):\n",
    "    avg_meters = {'loss': AverageMeter(),\n",
    "                  'iou': AverageMeter()}\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(total=len(val_loader))\n",
    "        for input, target, _ in val_loader:\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            if config['deep_supervision']:\n",
    "                outputs = model(input)\n",
    "                loss = 0\n",
    "                for output in outputs:\n",
    "                    loss += criterion(output, target)\n",
    "                loss /= len(outputs)\n",
    "                iou = iou_score(outputs[-1], target)\n",
    "            else:\n",
    "                output = model(input)\n",
    "                loss = criterion(output, target)\n",
    "                iou = iou_score(output, target)\n",
    "\n",
    "            avg_meters['loss'].update(loss.item(), input.size(0))\n",
    "            avg_meters['iou'].update(iou, input.size(0))\n",
    "\n",
    "            postfix = OrderedDict([\n",
    "                ('loss', avg_meters['loss'].avg),\n",
    "                ('iou', avg_meters['iou'].avg),\n",
    "            ])\n",
    "            pbar.set_postfix(postfix)\n",
    "            pbar.update(1)\n",
    "        pbar.close()\n",
    "\n",
    "    return OrderedDict([('loss', avg_meters['loss'].avg),\n",
    "                        ('iou', avg_meters['iou'].avg)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function (criterion)\n",
    "if config['loss'] == 'BCEWithLogitsLoss':\n",
    "    criterion = nn.BCEWithLogitsLoss().cuda()\n",
    "elif config['loss'] == 'BCEDiceLoss':\n",
    "    criterion = BCEDiceLoss().cuda()\n",
    "else:\n",
    "    criterion = LovaszHingeLoss().cuda()\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "model = {} # Use your NAS architecture here\n",
    "\n",
    "params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "\n",
    "if config['optimizer'] == 'Adam':\n",
    "    optimizer = optim.Adam(\n",
    "        params, lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "elif config['optimizer'] == 'SGD':\n",
    "    optimizer = optim.SGD(params, lr=config['lr'], momentum=config['momentum'],\n",
    "                          nesterov=config['nesterov'], weight_decay=config['weight_decay'])\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "if config['scheduler'] == 'CosineAnnealingLR':\n",
    "    scheduler = lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, T_max=config['epochs'], eta_min=config['min_lr'])\n",
    "elif config['scheduler'] == 'ReduceLROnPlateau':\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, factor=config['factor'], patience=config['patience'],\n",
    "                                                verbose=1, min_lr=config['min_lr'])\n",
    "elif config['scheduler'] == 'MultiStepLR':\n",
    "    scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[int(e) for e in config['milestones'].split(',')], gamma=config['gamma'])\n",
    "elif config['scheduler'] == 'ConstantLR':\n",
    "    scheduler = None\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    Compose, \n",
    "    RandRotate90, \n",
    "    RandFlip, \n",
    "    OneOf, \n",
    "    RandAdjustContrast, \n",
    "    RandGaussianNoise,  # MONAI does not directly support RandomBrightness, using Gaussian noise as an alternative\n",
    "    RandGaussianSharpen,  # MONAI does not have a direct match for RandomContrast, using Gaussian sharpen as an alternative\n",
    "    RandShiftIntensity,  # Alternative for adjusting brightness\n",
    "    Resize,\n",
    "    NormalizeIntensity\n",
    ")\n",
    "\n",
    "# Data loading code\n",
    "img_ids = glob(os.path.join('inputs', config['dataset'], 'images', '*' + config['img_ext']))\n",
    "img_ids = [os.path.splitext(os.path.basename(p))[0] for p in img_ids]\n",
    "\n",
    "train_img_ids, val_img_ids = train_test_split(img_ids, test_size=0.2, random_state=41)\n",
    "\n",
    "\n",
    "train_transform = Compose([\n",
    "    RandRotate90(prob=0.5, spatial_axes=(0, 1)),  # Randomly rotates the images by 90 degrees with a default probability of 0.5\n",
    "    RandFlip(prob=0.5, spatial_axis=0),  # Randomly flips the image along a given axis\n",
    "    OneOf([  # Applies one of the transforms\n",
    "        RandShiftIntensity(offsets=0.1, prob=1.0),  # Randomly shifts intensity for brightness adjustment\n",
    "        RandAdjustContrast(prob=1.0),  # Randomly changes contrast\n",
    "        RandGaussianSharpen(prob=1.0),  # Randomly sharpens the image\n",
    "    ]),\n",
    "    Resize(spatial_size=(config['input_h'], config['input_w'])),  # Resize images to a specified size\n",
    "    NormalizeIntensity(nonzero=True, channel_wise=True)  # Normalize pixel values with channel-wise option\n",
    "])\n",
    "\n",
    "val_transform = Compose([\n",
    "    Resize(spatial_size=(config['input_h'], config['input_w'])),  # Resize images to a specified size\n",
    "    NormalizeIntensity(nonzero=True, channel_wise=True)  # Normalize pixel values with channel-wise option\n",
    "])\n",
    "\n",
    "from analogainas.search_spaces.dataloaders.Nuclei_Dataset import Dataset as Dataset\n",
    "\n",
    "train_dataset = Dataset(\n",
    "    img_ids=train_img_ids,\n",
    "    img_dir=os.path.join('inputs', config['dataset'], 'images'),\n",
    "    mask_dir=os.path.join('inputs', config['dataset'], 'masks'),\n",
    "    img_ext=config['img_ext'],\n",
    "    mask_ext=config['mask_ext'],\n",
    "    num_classes=config['num_classes'],\n",
    "    transform=train_transform)\n",
    "\n",
    "val_dataset = Dataset(\n",
    "    img_ids=val_img_ids,\n",
    "    img_dir=os.path.join('inputs', config['dataset'], 'images'),\n",
    "    mask_dir=os.path.join('inputs', config['dataset'], 'masks'),\n",
    "    img_ext=config['img_ext'],\n",
    "    mask_ext=config['mask_ext'],\n",
    "    num_classes=config['num_classes'],\n",
    "    transform=val_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=config['num_workers'],\n",
    "    drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=config['num_workers'],\n",
    "    drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digital Training Loop\n",
    "\n",
    "log = OrderedDict([\n",
    "    ('epoch', []),\n",
    "    ('lr', []),\n",
    "    ('loss', []),\n",
    "    ('iou', []),\n",
    "    ('val_loss', []),\n",
    "    ('val_iou', []),\n",
    "])\n",
    "\n",
    "best_iou = 0\n",
    "trigger = 0\n",
    "for epoch in range(config['epochs']):\n",
    "    print('Epoch [%d/%d]' % (epoch, config['epochs']))\n",
    "\n",
    "    # train for one epoch\n",
    "    train_log = train(config, train_loader, model, criterion, optimizer)\n",
    "    # evaluate on validation set\n",
    "    val_log = validate(config, val_loader, model, criterion)\n",
    "\n",
    "    if config['scheduler'] == 'CosineAnnealingLR':\n",
    "        scheduler.step()\n",
    "    elif config['scheduler'] == 'ReduceLROnPlateau':\n",
    "        scheduler.step(val_log['loss'])\n",
    "\n",
    "    print('loss %.4f - iou %.4f - val_loss %.4f - val_iou %.4f'\n",
    "          % (train_log['loss'], train_log['iou'], val_log['loss'], val_log['iou']))\n",
    "\n",
    "    log['epoch'].append(epoch)\n",
    "    log['lr'].append(config['lr'])\n",
    "    log['loss'].append(train_log['loss'])\n",
    "    log['iou'].append(train_log['iou'])\n",
    "    log['val_loss'].append(val_log['loss'])\n",
    "    log['val_iou'].append(val_log['iou'])\n",
    "\n",
    "    pd.DataFrame(log).to_csv('models/%s/log.csv' %\n",
    "                              config['name'], index=False)\n",
    "\n",
    "    trigger += 1\n",
    "\n",
    "    if val_log['iou'] > best_iou:\n",
    "        torch.save(model.state_dict(), 'models/%s/model.pth' %\n",
    "                    config['name'])\n",
    "        best_iou = val_log['iou']\n",
    "        print(\"=> saved best model\")\n",
    "        trigger = 0\n",
    "\n",
    "    # early stopping\n",
    "    if config['early_stopping'] >= 0 and trigger >= config['early_stopping']:\n",
    "        print(\"=> early stopping\")\n",
    "        break\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analogainas.search_spaces.resnet_macro_architecture import Network\n",
    "from analogainas.search_spaces.train import train_config_unet\n",
    "from analogainas.utils import *\n",
    "\n",
    "# Building the Optimal Sub-network\n",
    "model = Network(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "supernetwork_nas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
