{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "890cd136",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3be4af41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyvww in /u/analognas/.conda/envs/aihwkit/lib/python3.6/site-packages (0.1.1)\n",
      "Requirement already satisfied: pycocotools in /u/analognas/.conda/envs/aihwkit/lib/python3.6/site-packages (from pyvww) (2.0.4)\n",
      "Requirement already satisfied: torchvision in /u/analognas/.conda/envs/aihwkit/lib/python3.6/site-packages (from pyvww) (0.9.1)\n",
      "Requirement already satisfied: numpy in /u/analognas/.conda/envs/aihwkit/lib/python3.6/site-packages (from pycocotools->pyvww) (1.19.5)\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /u/analognas/.conda/envs/aihwkit/lib/python3.6/site-packages (from pycocotools->pyvww) (3.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /u/analognas/.conda/envs/aihwkit/lib/python3.6/site-packages (from matplotlib>=2.1.0->pycocotools->pyvww) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /u/analognas/.conda/envs/aihwkit/lib/python3.6/site-packages (from matplotlib>=2.1.0->pycocotools->pyvww) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /u/analognas/.conda/envs/aihwkit/lib/python3.6/site-packages (from matplotlib>=2.1.0->pycocotools->pyvww) (8.4.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /u/analognas/.conda/envs/aihwkit/lib/python3.6/site-packages (from matplotlib>=2.1.0->pycocotools->pyvww) (3.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /u/analognas/.conda/envs/aihwkit/lib/python3.6/site-packages (from matplotlib>=2.1.0->pycocotools->pyvww) (1.3.1)\n",
      "Requirement already satisfied: six>=1.5 in /u/analognas/.conda/envs/aihwkit/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib>=2.1.0->pycocotools->pyvww) (1.16.0)\n",
      "Requirement already satisfied: torch==1.8.1 in /u/analognas/.conda/envs/aihwkit/lib/python3.6/site-packages (from torchvision->pyvww) (1.8.1)\n",
      "Requirement already satisfied: dataclasses in /u/analognas/.conda/envs/aihwkit/lib/python3.6/site-packages (from torch==1.8.1->torchvision->pyvww) (0.7)\n",
      "Requirement already satisfied: typing-extensions in /u/analognas/.conda/envs/aihwkit/lib/python3.6/site-packages (from torch==1.8.1->torchvision->pyvww) (4.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyvww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c9fca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from functools import partial\n",
    "from sqlite3 import SQLITE_REINDEX\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import torch \n",
    "from torch import device\n",
    "import torch.nn as nn\n",
    "import pyvww\n",
    "\n",
    "from aihwkit.nn import AnalogConv2d, AnalogLinear, AnalogSequential\n",
    "from aihwkit.optim import AnalogSGD\n",
    "from aihwkit.simulator.configs import SingleRPUConfig\n",
    "from aihwkit.simulator.configs.devices import ConstantStepDevice\n",
    "from aihwkit.simulator.rpu_base import cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7342bd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = 0\n",
    "if cuda.is_compiled():\n",
    "    USE_CUDA = 1\n",
    "DEVICE = device('cuda' if USE_CUDA else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5460e65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5e9a04",
   "metadata": {},
   "source": [
    "### Dataset: VWW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "593f50e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'visualwakewords'...\n",
      "remote: Enumerating objects: 79, done.\u001b[K\n",
      "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
      "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
      "remote: Total 79 (delta 1), reused 6 (delta 1), pack-reused 71\u001b[K\n",
      "Unpacking objects: 100% (79/79), 892.43 KiB | 2.62 MiB/s, done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Mxbonn/visualwakewords.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac3589ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping download of train2014.zip\n",
      "Unzipping train2014.zip\n",
      "train2014/COCO_train2014_000000297665.jpg:  write error (disk full?).  Continue? (y/n/^C) ^C\n"
     ]
    }
   ],
   "source": [
    "!bash visualwakewords/scripts/download_mscoco.sh dataset 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a4f9d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating COCO Annotation files\n",
    "!python visualwakewords/scripts/create_coco_train_minival_split.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5a1c929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all2014  annotations  train2014  val2014\r\n"
     ]
    }
   ],
   "source": [
    "!ls /dccstor/vww_dataset/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc6c56d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /dccstor/vww_dataset/dataset/annotations/instances_maxitrain.json...\n",
      "loading annotations into memory...\n",
      "Done (t=15.18s)\n",
      "creating index...\n",
      "index created!\n",
      "There are 55233 images that now have label person, of the 115228 images in total.\n",
      "Processing /dccstor/vww_dataset/dataset/annotations/instances_minival.json...\n",
      "loading annotations into memory...\n",
      "Done (t=0.64s)\n",
      "creating index...\n",
      "index created!\n",
      "There are 3800 images that now have label person, of the 8059 images in total.\n"
     ]
    }
   ],
   "source": [
    "# Creating VWW Annotation files \n",
    "MAXITRAIN_ANNOTATIONS_FILE=\"/dccstor/vww_dataset/dataset/annotations/instances_maxitrain.json\"\n",
    "MINIVAL_ANNOTATIONS_FILE=\"/dccstor/vww_dataset/dataset/annotations/instances_minival.json\"\n",
    "VWW_OUTPUT_DIR=\"/dccstor/vww_dataset/visualwakewords-dataset/annotations/\"\n",
    "\n",
    "!python visualwakewords/scripts/create_visualwakewords_annotations.py \\\n",
    "  --train_annotations_file=\"${MAXITRAIN_ANNOTATIONS_FILE}\" \\\n",
    "  --val_annotations_file=\"${MINIVAL_ANNOTATIONS_FILE}\" \\\n",
    "  --output_dir=\"${VWW_OUTPUT_DIR}\" \\\n",
    "  --threshold=0.005 \\\n",
    "  --foreground_class='person'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a09dc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=3.45s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.20s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(100),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = pyvww.pytorch.VisualWakeWordsClassification(root=\"/dccstor/vww_dataset/dataset/all2014\", \n",
    "                    annFile=\"/dccstor/vww_dataset/dataset/visualwakewords-dataset/annotations/instances_train.json\", transform= transform) \n",
    "valid_dataset = pyvww.pytorch.VisualWakeWordsClassification(root=\"/dccstor/vww_dataset/dataset/all2014\", \n",
    "                    annFile=\"/dccstor/vww_dataset/dataset/visualwakewords-dataset/annotations/instances_val.json\", transform= transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8acc37ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9882, 0.9294, 0.9843,  ..., 0.5804, 0.4784, 0.4627],\n",
       "         [0.6980, 0.4588, 0.7333,  ..., 0.6941, 0.6745, 0.6275],\n",
       "         [0.6078, 0.4039, 0.4667,  ..., 0.9373, 0.8510, 0.5451],\n",
       "         ...,\n",
       "         [0.6196, 0.5137, 0.6824,  ..., 0.3333, 0.6627, 0.4039],\n",
       "         [0.6078, 0.3647, 0.5412,  ..., 0.1647, 0.0000, 0.0549],\n",
       "         [0.2549, 0.0471, 0.4314,  ..., 0.6392, 0.2118, 0.2157]],\n",
       "\n",
       "        [[1.0000, 0.9333, 0.9843,  ..., 0.6118, 0.5137, 0.5137],\n",
       "         [0.7490, 0.4941, 0.7608,  ..., 0.7216, 0.6784, 0.6392],\n",
       "         [0.6902, 0.4824, 0.5373,  ..., 0.9294, 0.8471, 0.5529],\n",
       "         ...,\n",
       "         [0.6000, 0.5020, 0.6824,  ..., 0.3725, 0.7373, 0.4275],\n",
       "         [0.5961, 0.3529, 0.5490,  ..., 0.2392, 0.0118, 0.1216],\n",
       "         [0.2510, 0.0549, 0.4510,  ..., 0.6980, 0.2157, 0.2392]],\n",
       "\n",
       "        [[1.0000, 0.9529, 0.9922,  ..., 0.6235, 0.5490, 0.5451],\n",
       "         [0.6392, 0.4118, 0.6980,  ..., 0.7922, 0.7882, 0.6588],\n",
       "         [0.5216, 0.2902, 0.3490,  ..., 0.9804, 0.8706, 0.5490],\n",
       "         ...,\n",
       "         [0.5843, 0.4745, 0.6431,  ..., 0.4078, 0.7137, 0.6314],\n",
       "         [0.5765, 0.3176, 0.4941,  ..., 0.5412, 0.2902, 0.4275],\n",
       "         [0.2353, 0.0118, 0.3647,  ..., 0.9137, 0.4667, 0.4353]]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, target = train_dataset[5]\n",
    "display(target)\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6edd6d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (3, 100, 100) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f195fe10a090>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mann_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvww\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetAnnIds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgIds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfull_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvww\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadAnns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mann_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvww\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowAnns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aihwkit/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2728\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m         \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2730\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m   2731\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2732\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aihwkit/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1447\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aihwkit/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5521\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5523\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5524\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5525\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aihwkit/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    710\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    711\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 712\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (3, 100, 100) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_id = train_dataset.ids[5]\n",
    "ann_ids = train_dataset.vww.getAnnIds(imgIds=img_id)\n",
    "full_target = train_dataset.vww.loadAnns(ann_ids)\n",
    "plt.imshow(img)\n",
    "train_dataset.vww.showAnns(full_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be75c68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af4a485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RPU_CONFIG = SingleRPUConfig(device=ConstantStepDevice())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2c7b63",
   "metadata": {},
   "source": [
    "### Model Definition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2834d961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import List, Tuple\n",
    "import torch.nn.functional as F\n",
    "# Calculate asymmetric TensorFlow-like 'SAME' padding for a convolution\n",
    "def get_same_padding(x: int, k: int, s: int, d: int):\n",
    "    return max((math.ceil(x / s) - 1) * s + (k - 1) * d + 1 - x, 0)\n",
    "\n",
    "# Dynamically pad input x with 'SAME' padding for conv with specified args\n",
    "def pad_same(x, k: List[int], s: List[int], d: List[int] = 1, value: float = 0):\n",
    "    ih, iw = x.size()[-2:]\n",
    "    pad_h, pad_w = get_same_padding(ih, k, s, d), get_same_padding(iw, k, s, d)\n",
    "    if pad_h > 0 or pad_w > 0:\n",
    "        x = F.pad(x, [pad_w // 2, pad_w - pad_w // 2, pad_h // 2, pad_h - pad_h // 2], value=value)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e855a102",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNAct(nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        kernel_size: int,\n",
    "        stride: int,\n",
    "        padding: int = None,\n",
    "        norm: nn.Module = nn.BatchNorm2d,\n",
    "        act: nn.Module = nn.ReLU, \n",
    "        rpu_config = RPU_CONFIG,\n",
    "    ):\n",
    "        if padding: \n",
    "            super().__init__(\n",
    "                AnalogConv2d(\n",
    "                    in_features,\n",
    "                    out_features,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding= padding,\n",
    "                    rpu_config=RPU_CONFIG\n",
    "                ),\n",
    "                norm(out_features),\n",
    "                act(inplace=False),\n",
    "            )\n",
    "        else: \n",
    "            super().__init__(\n",
    "                AnalogConv2d(\n",
    "                    in_features,\n",
    "                    out_features,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    rpu_config=RPU_CONFIG\n",
    "                ),\n",
    "                norm(out_features),\n",
    "                act(inplace=False),\n",
    "            )\n",
    "        \n",
    "Conv1X1BnReLU = partial(ConvBNAct, kernel_size=1, stride=2)\n",
    "Conv3X3BnReLU = partial(ConvBNAct, kernel_size=3, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79163acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fused_MBConv(nn.Module):\n",
    "    def __init__(self, in_features: int, out_features: int, stride: int, expansion: int, residual = True):\n",
    "        #expanded_features = in_features * expansion\n",
    "        super().__init__()\n",
    "        #padding = get_same_padding()\n",
    "        self.stride = stride\n",
    "        self.block = nn.Sequential(\n",
    "                    nn.Sequential(\n",
    "                        # wide -> wide\n",
    "                        Conv3X3BnReLU(in_features, \n",
    "                                      expansion, \n",
    "                                      stride= stride,\n",
    "                                      act=nn.ReLU\n",
    "                                     ),\n",
    "                        # wide -> narrow-\n",
    "                        Conv1X1BnReLU(expansion, out_features, stride=1,padding=1, act=nn.Identity),\n",
    "                    ),\n",
    "                nn.ReLU(inplace=False),\n",
    "            )\n",
    "        self.residual = residual\n",
    "        \n",
    "    def forward(self, x): \n",
    "        x = pad_same(x, 3, self.stride)\n",
    "        x1 = self.block(x)\n",
    "        if self.residual: \n",
    "            x1 = x1 + x.clone() \n",
    "        return x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e390eafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.8.1+cu102'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26b55616",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalogNetVWW(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = ConvBNAct(3,12,3,2,1)\n",
    "        self.blocks = []\n",
    "        \n",
    "        # Each block is defined by the in/out channels, expansion, residual and stride\n",
    "        input_channels = [12,24,24,28,28,28,24,24,24,23,16,28,28,16,16,32]\n",
    "        expansion = [28,28,128,152,152,152,112,112,76,76,56,56,56,96,96,128]\n",
    "        residuals = [False, True, False, True, True, False, True, True, False, False, False, False, False, False, False]\n",
    "        stride = [2,1,2,1,1,2,1,1,1,1,1,1,2,1,1]\n",
    "        \n",
    "        self.nb_blocks = 15\n",
    "        for i in range(self.nb_blocks):\n",
    "            self.blocks.append(fused_MBConv(input_channels[i],input_channels[i+1], stride[i], \n",
    "                                            expansion[i], residuals[i]))\n",
    "        \n",
    "        self.blocks = nn.Sequential(*self.blocks)\n",
    "        self.pool = nn.AvgPool2d(3, stride=1)\n",
    "        self.linear = nn.Linear(9248, 2)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        x = self.layer1(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        return torch.softmax(self.linear(x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f059bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AnalogNetVWW()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "173aed3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnalogNetVWW(\n",
       "  (layer1): ConvBNAct(\n",
       "    (0): AnalogConv2d(3, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), digital bias)\n",
       "    (1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (blocks): Sequential(\n",
       "    (0): fused_MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvBNAct(\n",
       "            (0): AnalogConv2d(12, 28, kernel_size=(3, 3), stride=(2, 2), digital bias)\n",
       "            (1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvBNAct(\n",
       "            (0): AnalogConv2d(28, 24, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1): fused_MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvBNAct(\n",
       "            (0): AnalogConv2d(24, 28, kernel_size=(3, 3), stride=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvBNAct(\n",
       "            (0): AnalogConv2d(28, 24, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (2): fused_MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvBNAct(\n",
       "            (0): AnalogConv2d(24, 128, kernel_size=(3, 3), stride=(2, 2), digital bias)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvBNAct(\n",
       "            (0): AnalogConv2d(128, 28, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (3): fused_MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvBNAct(\n",
       "            (0): AnalogConv2d(28, 152, kernel_size=(3, 3), stride=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvBNAct(\n",
       "            (0): AnalogConv2d(152, 28, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (4): fused_MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvBNAct(\n",
       "            (0): AnalogConv2d(28, 152, kernel_size=(3, 3), stride=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvBNAct(\n",
       "            (0): AnalogConv2d(152, 28, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (5): fused_MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvBNAct(\n",
       "            (0): AnalogConv2d(28, 152, kernel_size=(3, 3), stride=(2, 2), digital bias)\n",
       "            (1): BatchNorm2d(152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvBNAct(\n",
       "            (0): AnalogConv2d(152, 24, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (6): fused_MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvBNAct(\n",
       "            (0): AnalogConv2d(24, 112, kernel_size=(3, 3), stride=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvBNAct(\n",
       "            (0): AnalogConv2d(112, 24, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (7): fused_MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvBNAct(\n",
       "            (0): AnalogConv2d(24, 112, kernel_size=(3, 3), stride=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvBNAct(\n",
       "            (0): AnalogConv2d(112, 24, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (8): fused_MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvBNAct(\n",
       "            (0): AnalogConv2d(24, 76, kernel_size=(3, 3), stride=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvBNAct(\n",
       "            (0): AnalogConv2d(76, 23, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (9): fused_MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvBNAct(\n",
       "            (0): AnalogConv2d(23, 76, kernel_size=(3, 3), stride=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(76, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvBNAct(\n",
       "            (0): AnalogConv2d(76, 16, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (10): fused_MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvBNAct(\n",
       "            (0): AnalogConv2d(16, 56, kernel_size=(3, 3), stride=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvBNAct(\n",
       "            (0): AnalogConv2d(56, 28, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (11): fused_MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvBNAct(\n",
       "            (0): AnalogConv2d(28, 56, kernel_size=(3, 3), stride=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvBNAct(\n",
       "            (0): AnalogConv2d(56, 28, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (12): fused_MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvBNAct(\n",
       "            (0): AnalogConv2d(28, 56, kernel_size=(3, 3), stride=(2, 2), digital bias)\n",
       "            (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvBNAct(\n",
       "            (0): AnalogConv2d(56, 16, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (13): fused_MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvBNAct(\n",
       "            (0): AnalogConv2d(16, 96, kernel_size=(3, 3), stride=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvBNAct(\n",
       "            (0): AnalogConv2d(96, 16, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (14): fused_MBConv(\n",
       "      (block): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): ConvBNAct(\n",
       "            (0): AnalogConv2d(16, 96, kernel_size=(3, 3), stride=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): ConvBNAct(\n",
       "            (0): AnalogConv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), padding=(1, 1), digital bias)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pool): AvgPool2d(kernel_size=3, stride=1, padding=0)\n",
       "  (linear): Linear(in_features=9248, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6377bfa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49781778 0.50218225]]\n"
     ]
    }
   ],
   "source": [
    "# test model \n",
    "dummy_input = torch.randn([1, 3, 100, 100])\n",
    "model.eval()\n",
    "np_torch_out = model(dummy_input).data.numpy()\n",
    "print(np_torch_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d071bcad",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a912c37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "SEED = 1\n",
    "N_EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.1\n",
    "N_CLASSES = 2\n",
    "WEIGHT_SCALING_OMEGA = 0.6  # Should not be larger than max weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "854a0f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sgd_optimizer(model, learning_rate):\n",
    "    \"\"\"Create the analog-aware optimizer.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): model to be trained\n",
    "        learning_rate (float): global parameter to define learning rate\n",
    "    Returns:\n",
    "        Optimizer: optimizer\n",
    "    \"\"\"\n",
    "    optimizer = AnalogSGD(model.parameters(), lr=learning_rate)\n",
    "    optimizer.regroup_param_groups(model)\n",
    "\n",
    "    return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36d057a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_step(train_data, model, criterion, optimizer):\n",
    "    \"\"\"Train network.\n",
    "\n",
    "    Args:\n",
    "        train_data (DataLoader): Validation set to perform the evaluation\n",
    "        model (nn.Module): Trained model to be evaluated\n",
    "        criterion (nn.CrossEntropyLoss): criterion to compute loss\n",
    "        optimizer (Optimizer): analog model optimizer\n",
    "\n",
    "    Returns:\n",
    "        nn.Module, Optimizer, float: model, optimizer, and epoch loss\n",
    "    \"\"\"\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for images, labels in train_data:\n",
    "        print(\"START\")\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Add training Tensor to the model (input).\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "\n",
    "        # Run training (backward propagation).\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimize weights.\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        print(total_loss)\n",
    "    epoch_loss = total_loss / len(train_data.dataset)\n",
    "\n",
    "    return model, optimizer, epoch_loss\n",
    "\n",
    "\n",
    "def test_evaluation(validation_data, model, criterion):\n",
    "    \"\"\"Test trained network\n",
    "\n",
    "    Args:\n",
    "        validation_data (DataLoader): Validation set to perform the evaluation\n",
    "        model (nn.Module): Trained model to be evaluated\n",
    "        criterion (nn.CrossEntropyLoss): criterion to compute loss\n",
    "\n",
    "    Returns:\n",
    "        nn.Module, float, float, float: model, test epoch loss, test error, and test accuracy\n",
    "    \"\"\"\n",
    "    total_loss = 0\n",
    "    predicted_ok = 0\n",
    "    total_images = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for images, labels in validation_data:\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "\n",
    "        pred = model(images)\n",
    "        loss = criterion(pred, labels)\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "\n",
    "        _, predicted = torch_max(pred.data, 1)\n",
    "        total_images += labels.size(0)\n",
    "        predicted_ok += (predicted == labels).sum().item()\n",
    "        accuracy = predicted_ok/total_images*100\n",
    "        error = (1-predicted_ok/total_images)*100\n",
    "\n",
    "    epoch_loss = total_loss / len(validation_data.dataset)\n",
    "\n",
    "    return model, epoch_loss, error, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ffba253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, criterion, optimizer, train_data, validation_data, epochs, print_every=1):\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    test_error = []\n",
    "\n",
    "    # Train model\n",
    "    for epoch in range(0, epochs):\n",
    "        # Train_step\n",
    "        torch.autograd.set_detect_anomaly(True)\n",
    "        model, optimizer, train_loss = train_step(train_data, model, criterion, optimizer)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        if epoch % print_every == (print_every - 1):\n",
    "            # Validate_step\n",
    "            with no_grad():\n",
    "                model, valid_loss, error, accuracy = test_evaluation(\n",
    "                    validation_data, model, criterion)\n",
    "                valid_losses.append(valid_loss)\n",
    "                test_error.append(error)\n",
    "\n",
    "            print(f'{datetime.now().time().replace(microsecond=0)} --- '\n",
    "                  f'Epoch: {epoch}\\t'\n",
    "                  f'Train loss: {train_loss:.4f}\\t'\n",
    "                  f'Valid loss: {valid_loss:.4f}\\t'\n",
    "                  f'Test error: {error:.2f}%\\t'\n",
    "                  f'Test accuracy: {accuracy:.2f}%\\t')\n",
    "\n",
    "    # Save results and plot figures\n",
    "    np.savetxt(os.path.join(RESULTS, \"Test_error.csv\"), test_error, delimiter=\",\")\n",
    "    np.savetxt(os.path.join(RESULTS, \"Train_Losses.csv\"), train_losses, delimiter=\",\")\n",
    "    np.savetxt(os.path.join(RESULTS, \"Valid_Losses.csv\"), valid_losses, delimiter=\",\")\n",
    "    plot_results(train_losses, valid_losses, test_error)\n",
    "\n",
    "    return model, optimizer, (train_losses, valid_losses, test_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d15122b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(train_losses, valid_losses, test_error):\n",
    "    \"\"\"Plot results.\n",
    "\n",
    "    Args:\n",
    "        train_losses (List): training losses as calculated in the training_loop\n",
    "        valid_losses (List): validation losses as calculated in the training_loop\n",
    "        test_error (List): test error as calculated in the training_loop\n",
    "    \"\"\"\n",
    "    fig = plt.plot(train_losses, 'r-s', valid_losses, 'b-o')\n",
    "    plt.title('aihwkit  AnalogNet-VWW')\n",
    "    plt.legend(fig[:2], ['Training Losses', 'Validation Losses'])\n",
    "    plt.xlabel('Epoch number')\n",
    "    plt.ylabel('Loss [A.U.]')\n",
    "    plt.grid(which='both', linestyle='--')\n",
    "    plt.savefig(os.path.join(RESULTS, 'test_losses.png'))\n",
    "    plt.close()\n",
    "\n",
    "    fig = plt.plot(test_error, 'r-s')\n",
    "    plt.title('aihwkit AnalogNet-VWW')\n",
    "    plt.legend(fig[:1], ['Test Error'])\n",
    "    plt.xlabel('Epoch number')\n",
    "    plt.ylabel('Test Error [%]')\n",
    "    plt.yscale('log')\n",
    "    plt.ylim((5e-1, 1e2))\n",
    "    plt.grid(which='both', linestyle='--')\n",
    "    plt.savefig(os.path.join(RESULTS, 'test_error.png'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae406509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n",
      "22.509504318237305\n",
      "START\n",
      "47.53272819519043\n",
      "START\n",
      "72.53085899353027\n",
      "START\n",
      "94.53685188293457\n",
      "START\n",
      "126.50631713867188\n",
      "START\n",
      "149.51226043701172\n",
      "START\n",
      "174.51644134521484\n",
      "START\n",
      "200.5413360595703\n",
      "START\n",
      "225.5609474182129\n",
      "START\n",
      "249.57230186462402\n",
      "START\n",
      "278.5701732635498\n",
      "START\n",
      "299.58553886413574\n",
      "START\n",
      "327.6038761138916\n",
      "START\n",
      "352.53384590148926\n",
      "START\n",
      "376.5626411437988\n",
      "START\n",
      "406.5526885986328\n",
      "START\n",
      "431.5181827545166\n",
      "START\n",
      "455.5213985443115\n",
      "START\n",
      "480.42695236206055\n",
      "START\n",
      "512.3888607025146\n",
      "START\n",
      "537.2624530792236\n",
      "START\n",
      "563.0433769226074\n",
      "START\n",
      "582.8069667816162\n",
      "START\n",
      "607.1594066619873\n",
      "START\n",
      "637.0866088867188\n",
      "START\n",
      "662.9751415252686\n",
      "START\n",
      "687.8255271911621\n",
      "START\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-ddce850a91ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m model, optimizer, _ = training_loop(model, criterion, optimizer, train_loader, valid_loader,\n\u001b[0;32m----> 6\u001b[0;31m                                     N_EPOCHS)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m print(f'{datetime.now().time().replace(microsecond=0)} --- '\n",
      "\u001b[0;32m<ipython-input-27-ee4f1208da20>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(model, criterion, optimizer, train_data, validation_data, epochs, print_every)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# Train_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-c84d7e00fdb8>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(train_data, model, criterion, optimizer)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Add training Tensor to the model (input).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aihwkit/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-d40fc584a459>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aihwkit/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aihwkit/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aihwkit/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-165461c4f38f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_same\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresidual\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aihwkit/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aihwkit/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aihwkit/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aihwkit/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aihwkit/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aihwkit/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aihwkit/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aihwkit/lib/python3.6/site-packages/aihwkit/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_input)\u001b[0m\n\u001b[1;32m    174\u001b[0m         out = AnalogIndexedFunction.apply(\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalog_tile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_analog_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             self.analog_tile.shared_weights, not self.training)\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_scaling_omega\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aihwkit/lib/python3.6/site-packages/aihwkit/nn/functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, analog_ctx, input_, shared_weights, is_test)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0manalog_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_indexed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         return AnalogFunctionBase.forward(\n\u001b[0;32m--> 127\u001b[0;31m             ctx, analog_ctx, input_, shared_weights, is_test)\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/aihwkit/lib/python3.6/site-packages/aihwkit/nn/functions.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, analog_ctx, input_, shared_weights, is_test)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# Invoke the forward pass in the tile instance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_indexed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0manalog_tile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_indexed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0manalog_tile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aihwkit/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/aihwkit/lib/python3.6/site-packages/aihwkit/simulator/tiles/base.py\u001b[0m in \u001b[0;36mforward_indexed\u001b[0;34m(self, x_input, is_test)\u001b[0m\n\u001b[1;32m    771\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTileError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'self.image_sizes length is not 3, 5 or 7'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_indexed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward_indexed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_input\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = create_sgd_optimizer(model, LEARNING_RATE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model, optimizer, _ = training_loop(model, criterion, optimizer, train_loader, valid_loader,\n",
    "                                    N_EPOCHS)\n",
    "\n",
    "print(f'{datetime.now().time().replace(microsecond=0)} --- '\n",
    "          f'Completed AnalogNet-VWW')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
